# ğŸ¤– RAG Chatbot in Amazon Bedrock

## ğŸš€ Project Overview
This project demonstrates how to set up a **Retrieval-Augmented Generation (RAG) chatbot** in **Amazon Bedrock**, leveraging **Amazon S3, OpenSearch Serverless**, and **Titan text embeddings v2** for efficient knowledge retrieval.

## ğŸ› ï¸ Technologies Used
- **Amazon Bedrock** â€“ AI model marketplace for generative AI applications  
- **Amazon S3** â€“ Storage for chatbot knowledge base  
- **OpenSearch Serverless** â€“ Vector search for retrieving relevant chunks of data  
- **Llama 3.3 70B** â€“ AI model for natural language processing  
- **Titan Text Embeddings v2** â€“ Fast and accurate embedding model for vector search  

## ğŸ“Œ Key Features
âœ”ï¸ **Retrieval-Augmented Generation (RAG):** Combines knowledge retrieval with generative AI  
âœ”ï¸ **Semantic Search with OpenSearch:** Finds relevant chunks of text based on meaning  
âœ”ï¸ **Scalable Knowledge Base:** Syncs with **Amazon S3** and updates dynamically  
âœ”ï¸ **Custom AI Model Access:** Uses **Llama 3.3 70B** for high-quality chatbot responses  

## ğŸ—ï¸ How It Works
1. **Upload Knowledge Base:** Store documents in **Amazon S3**  
2. **Embed & Chunk Data:** Convert text into vector representations  
3. **Store in OpenSearch:** Enables fast and meaningful retrieval  
4. **AI-Powered Responses:** The chatbot generates intelligent answers  

## ğŸ› ï¸ Challenges & Learnings
- **Model Access Error:** Llama 3.1 8B wasnâ€™t available, so I switched to Llama 3.3 70B  
- **Syncing Data:** Ensuring proper chunking and embeddings improved search accuracy  
- **Understanding Amazon Bedrock:** Explored how AWS handles generative AI models  

---
ğŸ”— **Connect with me on LinkedIn**: https://www.linkedin.com/in/pavan-gaggera
